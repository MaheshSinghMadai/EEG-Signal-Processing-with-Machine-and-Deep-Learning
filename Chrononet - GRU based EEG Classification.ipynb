{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e4870b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c2e314ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,inplace):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=inplace, out_channels=32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv1d(in_channels=inplace, out_channels=32, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=inplace, out_channels=32, kernel_size=8, stride=2, padding=3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x = torch.cat([x1,x2,x3], dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f1f06e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoNet(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super().__init__()\n",
    "        self.block1 = Block(channel)\n",
    "        self.block2 = Block(96)\n",
    "        self.block3 = Block(96)\n",
    "\n",
    "        self.gru1 = nn.GRU(input_size=96, hidden_size=32,batch_first=True)\n",
    "        self.gru2 = nn.GRU(input_size=32, hidden_size=32,batch_first=True)\n",
    "        self.gru3 = nn.GRU(input_size=64, hidden_size=32,batch_first=True)\n",
    "        self.gru4 = nn.GRU(input_size=96, hidden_size=32,batch_first=True)\n",
    "        \n",
    "        self.gru_linear = nn.Linear(64,1)\n",
    "        self.flattern = nn.Flatten()\n",
    "        self.fcl = nn.Linear(32,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        gru_out1,_ = self.gru1(x)\n",
    "        gru_out2,_= self.gru2(gru_out1)\n",
    "        gru_out = torch.cat([gru_out1, gru_out2], dim=2)\n",
    "\n",
    "        gru_out3,_ = self.gru3(gru_out)\n",
    "        gru_out = torch.cat([gru_out1,gru_out2, gru_out3], dim=2)\n",
    "        linear_out = self.relu(self.gru_linear(gru_out.permute(0,2,1)))\n",
    "\n",
    "        gru_out4,_ = self.gru4(linear_out.permute(0,2,1))\n",
    "        \n",
    "        x = self.flattern(gru_out4)\n",
    "        x = self.fcl(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "216e3bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3,14,512)\n",
    "input.shape\n",
    "model = ChronoNet(14)\n",
    "out = model(input)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "86c0ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import scipy.io\n",
    "import mne\n",
    "\n",
    "IDD = Path('EEG dataset/Data/CleanData/CLeanData_IDD/Rest')\n",
    "TDC = Path('EEG dataset/Data/CleanData/CLeanData_TDC/Rest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ed86250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMatToMNE(data):\n",
    "    ch_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "    ch_types = ['eeg'] * 14\n",
    "    sampling_freq = 128\n",
    "    info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "    info.set_montage('standard_1020')\n",
    "    \n",
    "    data = mne.io.RawArray(data,info)\n",
    "    # data.set_egg_reference()\n",
    "    data.filter(l_freq=1, h_freq=30)\n",
    "    epochs = mne.make_fixed_length_epochs(data, duration=4, overlap=0)\n",
    "    return epochs.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "45888f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "pattern = os.path.join(IDD, '*.mat')\n",
    "idd_files = glob(pattern)\n",
    "idd_subject = []\n",
    "\n",
    "for idd in idd_files:\n",
    "    data = scipy.io.loadmat(idd)['clean_data']\n",
    "    data = convertMatToMNE(data)\n",
    "    idd_subject.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "43612600",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "pattern = os.path.join(TDC, '*.mat')\n",
    "tdc_files = glob(pattern)\n",
    "tdc_subject = []\n",
    "\n",
    "for tdc in tdc_files:\n",
    "    data = scipy.io.loadmat(tdc)['clean_data']\n",
    "    data = convertMatToMNE(data)\n",
    "    tdc_subject.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2287a526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_epoch_labels = [len(i) *[0] for i in tdc_subject]\n",
    "patient_epoch_labels = [len(i) *[1] for i in idd_subject]    \n",
    "len(healthy_epoch_labels), len(patient_epoch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "597f4e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14, 14)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = tdc_subject + idd_subject\n",
    "labels_list = healthy_epoch_labels + patient_epoch_labels \n",
    "groups_list = [[i]*len(j) for i,j in enumerate(data_list)]\n",
    "len(data_list), len(labels_list), len(groups_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "19edd15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "gkf = GroupKFold()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9f73e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler3D(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scalar = StandardScaler()\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        self.scalar.fit(X.reshape(-1, X.shape[2]))\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return self.scalar.transform(X.reshape(-1,X.shape[2])).reshape(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "716e26fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 512, 14) (420,) (420,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_list = np.concatenate(data_list)\n",
    "labels_list = np.concatenate(labels_list)\n",
    "groups_list = np.concatenate(groups_list)\n",
    "data_list = np.moveaxis(data_list,1,2)\n",
    "\n",
    "print(data_list.shape, labels_list.shape, groups_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f0a28b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "\n",
    "for train_index, val_index in gkf.split(data_list, labels_list, groups=groups_list):\n",
    "    train_features, train_labels = data_list[train_index], labels_list[train_index]\n",
    "    val_features, val_labels = data_list[val_index], labels_list[val_index]\n",
    "\n",
    "    scaler = StandardScaler3D()\n",
    "\n",
    "    train_features = scaler.fit_transform(train_features)\n",
    "    val_features = scaler.transform(val_features)\n",
    "    train_features = np.moveaxis(train_features,1,2)\n",
    "    val_features = np.moveaxis(val_features,1,2)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0546ea4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 90)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = torch.Tensor(train_features)\n",
    "val_features = torch.Tensor(val_features)\n",
    "train_labels = torch.Tensor(train_labels)\n",
    "val_labels = torch.Tensor(val_labels)\n",
    "\n",
    "len(train_features), len(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ca3b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer\n",
    "import torchmetrics\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "85c14f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoModel(LightningModule):\n",
    "    def __init__ (self):\n",
    "        super(ChronoModel, self).__init__()\n",
    "        self.model=ChronoNet(14)\n",
    "        self.lr = 1e-3   #learning rate\n",
    "        self.bs = 12     #batch size\n",
    "        self.worker = 2   # no of worker\n",
    "        self.acc = torchmetrics.Accuracy(task='binary')\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.training_outputs = []\n",
    "        self.validation_outputs = []\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = TensorDataset(train_features, train_labels)\n",
    "        dataloader = DataLoader(dataset, batch_size = self.bs, num_workers =self.worker, shuffle = True)\n",
    "        return dataloader\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        signal, label = batch\n",
    "        out = self(signal.float())\n",
    "        loss = self.criterion(out.flatten(), label.float().flatten())\n",
    "        acc = self.acc(out.flatten(), label.long().flatten())\n",
    "        \n",
    "        output = { 'loss': loss, 'acc':acc }\n",
    "        self.training_outputs.append(output)\n",
    "        return output\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        acc = torch.stack([x['acc'] for x in self.training_outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        loss = torch.stack([x['loss'] for x in self.training_outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        print('train acc loss ', acc, loss)\n",
    "        self.training_outputs.clear()\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = TensorDataset(val_features, val_labels)\n",
    "        val_dataloader = DataLoader(dataset, batch_size = self.bs, num_workers =self.worker, shuffle = True)\n",
    "        return val_dataloader\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        signal, label = batch\n",
    "        out = self(signal.float())\n",
    "        loss = self.criterion(out.flatten(), label.float().flatten())\n",
    "        acc = self.acc(out.flatten(), label.long().flatten())\n",
    "        \n",
    "        output = { 'loss': loss, 'acc':acc }\n",
    "        self.validation_outputs.append(output)\n",
    "        return output\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        acc = torch.stack([x['acc'] for x in self.validation_outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        loss = torch.stack([x['loss'] for x in self.validation_outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        print('val acc loss ', acc, loss)\n",
    "        self.validation_outputs.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "39e3210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChronoModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "129e9409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1f9e9c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ model     â”‚ ChronoNet         â”‚  133 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ acc       â”‚ BinaryAccuracy    â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ criterion â”‚ BCEWithLogitsLoss â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ model     â”‚ ChronoNet         â”‚  133 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ acc       â”‚ BinaryAccuracy    â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ criterion â”‚ BCEWithLogitsLoss â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 133 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 133 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 26                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 133 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 133 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 26                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rich\\live.py:256: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connector\n",
       "s\\data_connector.py:485: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you\n",
       "turn shuffling off for val/test dataloaders.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connector\n",
       "s\\data_connector.py:485: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you\n",
       "turn shuffling off for val/test dataloaders.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connector\n",
       "s\\data_connector.py:429: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader \n",
       "worker initialization.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connector\n",
       "s\\data_connector.py:429: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader \n",
       "worker initialization.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">val acc loss  0.29 0.69\n",
       "</pre>\n"
      ],
      "text/plain": [
       "val acc loss  0.29 0.69\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connector\n",
       "s\\data_connector.py:429: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the \n",
       "dataloader worker initialization.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connector\n",
       "s\\data_connector.py:429: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the \n",
       "dataloader worker initialization.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py\n",
       ":317: The number of training batches (28) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py\n",
       ":317: The number of training batches (28) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a\n",
       "lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">val acc loss  0.35 0.7\n",
       "</pre>\n"
      ],
      "text/plain": [
       "val acc loss  0.35 0.7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">train acc loss  0.55 0.69\n",
       "</pre>\n"
      ],
      "text/plain": [
       "train acc loss  0.55 0.69\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98187aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

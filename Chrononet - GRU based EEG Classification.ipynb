{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4870b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2e314ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,inplace):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=inplace, out_channels=32, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv1d(in_channels=inplace, out_channels=32, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=inplace, out_channels=32, kernel_size=8, stride=2, padding=3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x = torch.cat([x1,x2,x3], dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1f06e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoNet(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super().__init__()\n",
    "        self.block1 = Block(channel)\n",
    "        self.block2 = Block(96)\n",
    "        self.block3 = Block(96)\n",
    "\n",
    "        self.gru1 = nn.GRU(input_size=96, hidden_size=32,batch_first=True)\n",
    "        self.gru2 = nn.GRU(input_size=32, hidden_size=32,batch_first=True)\n",
    "        self.gru3 = nn.GRU(input_size=64, hidden_size=32,batch_first=True)\n",
    "        self.gru4 = nn.GRU(input_size=96, hidden_size=32,batch_first=True)\n",
    "        \n",
    "        self.gru_linear = nn.Linear(64,1)\n",
    "        self.flattern = nn.Flatten()\n",
    "        self.fcl = nn.Linear(32,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        gru_out1,_ = self.gru1(x)\n",
    "        gru_out2,_= self.gru2(gru_out1)\n",
    "        gru_out = torch.cat([gru_out1, gru_out2], dim=2)\n",
    "\n",
    "        gru_out3,_ = self.gru3(gru_out)\n",
    "        gru_out = torch.cat([gru_out1,gru_out2, gru_out3], dim=2)\n",
    "        linear_out = self.relu(self.gru_linear(gru_out.permute(0,2,1)))\n",
    "\n",
    "        gru_out4,_ = self.gru4(linear_out.permute(0,2,1))\n",
    "        \n",
    "        x = self.flattern(gru_out4)\n",
    "        x = self.fcl(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "216e3bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3,14,512)\n",
    "input.shape\n",
    "model = ChronoNet(14)\n",
    "out = model(input)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86c0ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import scipy.io\n",
    "import mne\n",
    "\n",
    "IDD = Path('EEG dataset/Data/CleanData/CLeanData_IDD/Rest')\n",
    "TDC = Path('EEG dataset/Data/CleanData/CLeanData_TDC/Rest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed86250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMatToMNE(data):\n",
    "    ch_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "    ch_types = ['eeg'] * 14\n",
    "    sampling_freq = 128\n",
    "    info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "    info.set_montage('standard_1020')\n",
    "    \n",
    "    data = mne.io.RawArray(data,info)\n",
    "    # data.set_egg_reference()\n",
    "    data.filter(l_freq=1, h_freq=30)\n",
    "    epochs = mne.make_fixed_length_epochs(data, duration=4, overlap=0)\n",
    "    return epochs.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45888f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "pattern = os.path.join(IDD, '*.mat')\n",
    "idd_files = glob(pattern)\n",
    "idd_subject = []\n",
    "\n",
    "for idd in idd_files:\n",
    "    data = scipy.io.loadmat(idd)['clean_data']\n",
    "    data = convertMatToMNE(data)\n",
    "    idd_subject.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43612600",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "pattern = os.path.join(TDC, '*.mat')\n",
    "tdc_files = glob(pattern)\n",
    "tdc_subject = []\n",
    "\n",
    "for tdc in tdc_files:\n",
    "    data = scipy.io.loadmat(tdc)['clean_data']\n",
    "    data = convertMatToMNE(data)\n",
    "    tdc_subject.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2287a526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_epoch_labels = [len(i) *[0] for i in tdc_subject]\n",
    "patient_epoch_labels = [len(i) *[1] for i in idd_subject]    \n",
    "len(healthy_epoch_labels), len(patient_epoch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "597f4e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14, 14)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = tdc_subject + idd_subject\n",
    "labels_list = healthy_epoch_labels + patient_epoch_labels \n",
    "groups_list = [[i]*len(j) for i,j in enumerate(data_list)]\n",
    "len(data_list), len(labels_list), len(groups_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19edd15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "gkf = GroupKFold()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f73e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler3D(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.scalar = StandardScaler()\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        self.scalar.fit(X.reshape(-1, X.shape[2]))\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        return self.scalar.transform(X.reshape(-1,X.shape[2])).reshape(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "716e26fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 512, 14) (420,) (420,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_list = np.concatenate(data_list)\n",
    "labels_list = np.concatenate(labels_list)\n",
    "groups_list = np.concatenate(groups_list)\n",
    "data_list = np.moveaxis(data_list,1,2)\n",
    "\n",
    "print(data_list.shape, labels_list.shape, groups_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0a28b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "\n",
    "for train_index, val_index in gkf.split(data_list, labels_list, groups=groups_list):\n",
    "    train_features, train_labels = data_list[train_index], labels_list[train_index]\n",
    "    val_features, val_labels = data_list[val_index], labels_list[val_index]\n",
    "\n",
    "    scaler = StandardScaler3D()\n",
    "\n",
    "    train_features = scaler.fit_transform(train_features)\n",
    "    train_features = scaler.fit_transform(val_features)\n",
    "    train_features = np.moveaxis(train_features,1,2)\n",
    "    val_features = np.moveaxis(val_features,1,2)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0546ea4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 90)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = torch.Tensor(train_features)\n",
    "val_features = torch.Tensor(val_features)\n",
    "train_labels = torch.Tensor(train_labels)\n",
    "val_labels = torch.Tensor(val_labels)\n",
    "\n",
    "len(train_features), len(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ca3b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer\n",
    "import torchmetrics\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "85c14f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoModel(LightningModule):\n",
    "    def __init__ (self):\n",
    "        super(ChronoModel, self).__init__()\n",
    "        self.model=ChronoNet(14)\n",
    "        self.lr = 1e-3   #learning rate\n",
    "        self.bs = 12     #batch size\n",
    "        self.worker = 2   # no of worker\n",
    "        self.acc = torchmetrics.Accuracy(task='binary')\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters, lr=self.lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = TensorDataset(train_features, train_labels)\n",
    "        dataloader = DataLoader(dataset, batch_size = self.bs, num_workers =self.worker, shuffle = True)\n",
    "        return dataloader\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        signal, label = batch\n",
    "        out = self(signal.float())\n",
    "        loss = self.criterion(out.flatten(), label.float().flatten())\n",
    "        acc = self.acc(out.flatten(), label.long().flatten())\n",
    "        \n",
    "        return { 'loss': loss, 'acc':acc }\n",
    "    \n",
    "    def trained_epoch_end(self, outputs):\n",
    "        acc = torch.stack([x['acc'] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "\n",
    "        print('train acc loss ', acc, loss)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = TensorDataset(val_features, val_labels)\n",
    "        dataloader = dataloader(dataset, batch_size = self.bs, num_workers =self.worker, shuffle = True)\n",
    "        return dataloader\n",
    "    \n",
    "    def validation_step(self, batch,batch_idx):\n",
    "        signal, label = batch\n",
    "        out = self(signal.float())\n",
    "        loss = self.creterion(out.flatten(), label.float().flatten())\n",
    "        acc = self.acc(out.flatten(), label.long().flatten())\n",
    "        \n",
    "        return { 'loss': loss, 'acc':acc }\n",
    "    \n",
    "    def validated_epoch_end(self, outputs):\n",
    "        acc = torch.stack([x['acc'] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "\n",
    "        print('val acc loss ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39e3210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChronoModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "129e9409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f9e9c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:584\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path, weights_only)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     52\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:630\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path, weights_only)\u001b[39m\n\u001b[32m    623\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    624\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    625\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    626\u001b[39m     ckpt_path,\n\u001b[32m    627\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    628\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    629\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    633\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1053\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path, weights_only)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector.reset_metrics()\n\u001b[32m   1052\u001b[39m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.fn == TrainerFn.FITTING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:159\u001b[39m, in \u001b[36mStrategy.setup\u001b[39m\u001b[34m(self, trainer)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m._setup_model(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.state.fn == TrainerFn.FITTING:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28mself\u001b[39m.setup_precision_plugin()\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.state.fn == TrainerFn.FITTING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:139\u001b[39m, in \u001b[36mStrategy.setup_optimizers\u001b[39m\u001b[34m(self, trainer)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates optimizers and schedulers.\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m    134\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[33;03m    trainer: the Trainer, these optimizers should be connected to\u001b[39;00m\n\u001b[32m    136\u001b[39m \n\u001b[32m    137\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizers, \u001b[38;5;28mself\u001b[39m.lr_scheduler_configs = \u001b[43m_init_optimizers_and_lr_schedulers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:180\u001b[39m, in \u001b[36m_init_optimizers_and_lr_schedulers\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls `LightningModule.configure_optimizers` and parses and validates the output.\"\"\"\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytorch_lightning\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m call\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m optim_conf = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigure_optimizers\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optim_conf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    183\u001b[39m     rank_zero_warn(\n\u001b[32m    184\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    185\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:177\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m pl_module._current_fx_name = hook_name\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    180\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mChronoModel.configure_optimizers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconfigure_optimizers\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adam.py:101\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m defaults = {\n\u001b[32m     89\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: lr,\n\u001b[32m     90\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m: betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     99\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdecoupled_weight_decay\u001b[39m\u001b[33m\"\u001b[39m: decoupled_weight_decay,\n\u001b[32m    100\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:394\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28mself\u001b[39m.state: defaultdict[torch.Tensor, Any] = defaultdict(\u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    392\u001b[39m \u001b[38;5;28mself\u001b[39m.param_groups: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] = []\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m param_groups = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) == \u001b[32m0\u001b[39m:\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33moptimizer got an empty parameter list\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98187aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

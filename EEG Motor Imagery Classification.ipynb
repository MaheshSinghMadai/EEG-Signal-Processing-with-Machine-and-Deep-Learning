{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b41405f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5c3a4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== CONFIG ====================\n",
    "DATA_DIR = 'BCICIV_2a/'          # Folder containing A01T.gdf ... A09E.gdf\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LR = 0.001\n",
    "T_MIN = 0.0      # Start of epoch relative to cue\n",
    "T_MAX = 4.0      # 4-second trials (standard for this dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8213b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)   # [trials, channels, time]\n",
    "        self.labels   = torch.tensor(labels,   dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a97f6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRUModel(nn.Module):\n",
    "    def __init__(self, num_channels=22, num_classes=4, hidden_dim=128, dropout=0.5):\n",
    "        super().__init__()\n",
    "        # Spatial convolution to reduce channel dimension (common in EEG DL)\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(num_channels, 1), stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropout)\n",
    "        )\n",
    "\n",
    "        self.bigru = nn.GRU(input_size=32,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True,\n",
    "                            dropout=dropout)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, channels, time]\n",
    "        batch = x.size(0)\n",
    "        x = x.unsqueeze(1)                     # [batch, 1, channels, time]\n",
    "        x = self.spatial(x)                    # [batch, 32, 1, time]\n",
    "        x = x.squeeze(2)                       # [batch, 32, time]\n",
    "        x = x.permute(0, 2, 1)                 # [batch, time, 32] for GRU\n",
    "        _, hn = self.bigru(x)                  # hn: [4, batch, hidden] (2 layers × bidirectional)\n",
    "        hn = hn.view(2, 2, batch, -1)          # separate layers & directions\n",
    "        hn = hn[-1]                            # take top layer\n",
    "        hn = hn.transpose(0, 1).contiguous().view(batch, -1)  # [batch, hidden*2]\n",
    "        out = self.classifier(hn)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6eb06237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_data(subject_id, data_dir):\n",
    "    def preprocess_raw(raw):\n",
    "        raw.drop_channels(['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        raw.filter(8., 30.)                     # Mu/beta band\n",
    "        raw.set_eeg_reference('average')\n",
    "        return raw\n",
    "\n",
    "    sessions = ['T', 'E']\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for sess in sessions:\n",
    "        path = os.path.join(data_dir, f'{subject_id}{sess}.gdf')\n",
    "        raw = mne.io.read_raw_gdf(path, preload=True, eog=['EOG-left', 'EOG-central', 'EOG-right'])\n",
    "        raw = preprocess_raw(raw)\n",
    "        \n",
    "        events, event_id = mne.events_from_annotations(raw)\n",
    "    \n",
    "        # Standard event ids for classes (769=left, 770=right, 771=foot, 772=tongue)\n",
    "        picks = mne.pick_types(raw.info, eeg=True, eog=False)\n",
    "        \n",
    "        epochs = mne.Epochs(raw, events, event_id={'769':7, '770':8, '771':9, '772':10},\n",
    "                            tmin=0, tmax=4,  # Full 4s trial\n",
    "                            picks=picks, baseline=(0, 0),  # Or (None, 0) for no baseline\n",
    "                            preload=True, reject=dict(eeg=100e-6))\n",
    "\n",
    "        X_list.append(epochs.get_data())\n",
    "        y_list.append(epochs.events[:, -1] - 6)\n",
    "\n",
    "    X_train, X_test = X_list[0], X_list[1]\n",
    "    y_train, y_test = y_list[0], y_list[1]\n",
    "\n",
    "    print(f\"{subject_id}: Train trials {len(X_train)}, Test trials {len(X_test)}\")\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "01ba844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing subject A01 ===\n",
      "Extracting GDF parameters from BCICIV_2a/A01T.gdf...\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1001 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting GDF parameters from BCICIV_2a/A01E.gdf...\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "EEG-Fz, EEG, EEG, EEG, EEG, EEG, EEG, EEG-C3, EEG, EEG-Cz, EEG, EEG-C4, EEG, EEG, EEG, EEG, EEG, EEG, EEG, EEG-Pz, EEG, EEG\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 686999  =      0.000 ...  2747.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:144: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 8 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No matching events found for 770 (event id 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m subj \u001b[38;5;129;01min\u001b[39;00m subjects:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Processing subject \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     (X_train_full, y_train_full), (X_test, y_test) = \u001b[43mload_subject_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Split training session into train / validation\u001b[39;00m\n\u001b[32m     10\u001b[39m     X_train, X_val, y_train, y_val = train_test_split(\n\u001b[32m     11\u001b[39m         X_train_full, y_train_full, test_size=\u001b[32m0.2\u001b[39m, stratify=y_train_full, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mload_subject_data\u001b[39m\u001b[34m(subject_id, data_dir)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Standard event ids for classes (769=left, 770=right, 771=foot, 772=tongue)\u001b[39;00m\n\u001b[32m     19\u001b[39m picks = mne.pick_types(raw.info, eeg=\u001b[38;5;28;01mTrue\u001b[39;00m, eog=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m epochs = \u001b[43mmne\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEpochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m769\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m770\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m771\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m772\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mtmin\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmax\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Full 4s trial\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Or (None, 0) for no baseline\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mpreload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreject\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meeg\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100e-6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m X_list.append(epochs.get_data())\n\u001b[32m     27\u001b[39m y_list.append(epochs.events[:, -\u001b[32m1\u001b[39m] - \u001b[32m6\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-252>:12\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, raw, events, event_id, tmin, tmax, baseline, picks, preload, reject, flat, proj, decim, reject_tmin, reject_tmax, detrend, on_missing, reject_by_annotation, metadata, event_repeated, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mne\\epochs.py:3594\u001b[39m, in \u001b[36mEpochs.__init__\u001b[39m\u001b[34m(self, raw, events, event_id, tmin, tmax, baseline, picks, preload, reject, flat, proj, decim, reject_tmin, reject_tmax, detrend, on_missing, reject_by_annotation, metadata, event_repeated, verbose)\u001b[39m\n\u001b[32m   3589\u001b[39m             metadata = pd.concat(\n\u001b[32m   3590\u001b[39m                 [metadata, extras_df], axis=\u001b[32m1\u001b[39m, ignore_index=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3591\u001b[39m             )\n\u001b[32m   3593\u001b[39m \u001b[38;5;66;03m# call BaseEpochs constructor\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3594\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   3595\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3596\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreject_tmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreject_tmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreject_tmax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreject_tmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdetrend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetrend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_missing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_missing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_at_end\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent_repeated\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevent_repeated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_sfreq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_sfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3618\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-236>:12\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, info, data, events, event_id, tmin, tmax, baseline, raw, picks, reject, flat, decim, reject_tmin, reject_tmax, detrend, proj, on_missing, preload_at_end, selection, drop_log, filename, metadata, event_repeated, raw_sfreq, annotations, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mne\\epochs.py:491\u001b[39m, in \u001b[36mBaseEpochs.__init__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m events[:, \u001b[32m2\u001b[39m]:\n\u001b[32m    490\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo matching events found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (event id \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m         \u001b[43m_on_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;66;03m# ensure metadata matches original events size\u001b[39;00m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m.selection = np.arange(\u001b[38;5;28mlen\u001b[39m(events))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MrKillShOtzz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mne\\utils\\check.py:1221\u001b[39m, in \u001b[36m_on_missing\u001b[39m\u001b[34m(on_missing, msg, name, error_klass)\u001b[39m\n\u001b[32m   1219\u001b[39m on_missing = \u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_missing == \u001b[33m\"\u001b[39m\u001b[33mwarning\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m on_missing\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_missing == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_klass(msg)\n\u001b[32m   1222\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m on_missing == \u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1223\u001b[39m     warn(msg)\n",
      "\u001b[31mValueError\u001b[39m: No matching events found for 770 (event id 8)"
     ]
    }
   ],
   "source": [
    "subjects = [f'A0{i}' for i in range(1, 10)]   # A01 to A09\n",
    "results = {}\n",
    "\n",
    "for subj in subjects:\n",
    "    print(f\"\\n=== Processing subject {subj} ===\")\n",
    "\n",
    "    (X_train_full, y_train_full), (X_test, y_test) = load_subject_data(subj, DATA_DIR)\n",
    "\n",
    "    # Split training session into train / validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42)\n",
    "\n",
    "    train_ds = EEGDataset(X_train, y_train)\n",
    "    val_ds   = EEGDataset(X_val,   y_val)\n",
    "    test_ds  = EEGDataset(X_test,  y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = BiGRUModel().to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data = data.to(DEVICE)\n",
    "                output = model(data)\n",
    "                pred = output.argmax(dim=1)\n",
    "                val_preds.extend(pred.cpu().numpy())\n",
    "                val_true.extend(target.numpy())\n",
    "        val_acc = accuracy_score(val_true, val_preds)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'best_model_{subj}.pth')\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == EPOCHS:\n",
    "            print(f\"Epoch {epoch:2d} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Load best model and test on E session\n",
    "    model.load_state_dict(torch.load(f'best_model_{subj}.pth'))\n",
    "    model.eval()\n",
    "    test_preds, test_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(DEVICE)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            test_preds.extend(pred.cpu().numpy())\n",
    "            test_true.extend(target.numpy())\n",
    "\n",
    "    acc  = accuracy_score(test_true, test_preds)\n",
    "    kappa = cohen_kappa_score(test_true, test_preds)\n",
    "\n",
    "    results[subj] = {'accuracy': acc, 'kappa': kappa}\n",
    "    print(f\"{subj} Test Accuracy: {acc:.4f} | Kappa: {kappa:.4f}\")\n",
    "\n",
    "# ==================== SUMMARY ====================\n",
    "accs  = [v['accuracy'] for v in results.values()]\n",
    "kappas = [v['kappa'] for v in results.values()]\n",
    "\n",
    "print(\"\\n=== FINAL RESULTS (Subject-Dependent) ===\")\n",
    "for subj, res in results.items():\n",
    "    print(f\"{subj}: Acc = {res['accuracy']:.4f}, Kappa = {res['kappa']:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage Accuracy: {np.mean(accs):.4f} (±{np.std(accs):.3f})\")\n",
    "print(f\"Average Kappa:    {np.mean(kappas):.4f} (±{np.std(kappas):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fd4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
